import polars as pl
import logging
from typing import Optional

import narwhals.stable.v2 as nw
from narwhals.typing import IntoFrameT
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler

from spforge.features_generator import FeaturesGenerator
from spforge.predictor._base import BasePredictor
from spforge.predictor_transformer import PredictorTransformer, SkLearnTransformerWrapper, \
    ConvertDataFrameToCategoricalTransformer
from spforge.predictor_transformer._simple_transformer import SimpleTransformer

from spforge.scorer import Filter, apply_filters


class Pipeline(BasePredictor):


    def __init__(
            self,
            predictor: BasePredictor,
            filters: list[Filter] | None = None,
            scale_features: bool = False,
            one_hot_encode_cat_features: bool = False,
            convert_cat_features_to_cat_dtype: bool = False,
            impute_missing_values: bool = False,
            drop_rows_where_target_is_nan: bool = False,
            pre_transformers: Optional[list[PredictorTransformer]] = None,
            post_predict_transformers: Optional[list[SimpleTransformer]] = None,

    ):
        super().__init__(
            features=predictor.features,
            target=predictor.target,
            pred_column=predictor.pred_column,
            filters=filters,
            scale_features=scale_features,
            one_hot_encode_cat_features=one_hot_encode_cat_features,
            impute_missing_values=impute_missing_values,
            convert_cat_features_to_cat_dtype=convert_cat_features_to_cat_dtype,
            pre_transformers=pre_transformers,
            post_predict_transformers=post_predict_transformers
        )
        self.filters = filters or []
        self.drop_rows_where_target_is_nan = drop_rows_where_target_is_nan
        self._predictor_features = predictor.features.copy()

        if predictor.features_contain_str:
            logging.info(
                f"Using estimator features {self._predictor_features} and {predictor.features_contain_str}"
            )
        else:
            logging.info(f"Using estimator features {self._predictor_features}")
        self.predictor = predictor
        self._pred_columns_added = self.predictor._pred_columns_added

    @nw.narwhalify
    def train(self, df: IntoFrameT, features: Optional[list[str]] = None) -> None:
        """
        Trains the pipeline on the given dataframe and generates and returns predictions.
        :param df: DataFrame with the data to be used for training and prediction
        """
        if self.predictor.target not in df.columns:
            raise ValueError(
                f"Target {self.predictor.target} not in df columns. Available columns: {df.columns}"
            )

        features = features or self._predictor_features
        self._features = (
            features.copy() if features else self._ori_estimator_features.copy()
        )
        self._modified_features = self._features.copy()
        if not self._features:
            raise ValueError(
                "features not set. Either pass to train or pass when instantiating predictor object"
            )

        self._add_features_contain_str(df)

        filtered_df = apply_filters(df=df, filters=self.filters)
        if self.drop_rows_where_target_is_nan:
            filtered_df = filtered_df.filter(~nw.col(self._target).is_nan())
        filtered_df = self._fit_transform_pre_transformers(df=filtered_df)
        self.predictor.train(df=filtered_df, features=self._modified_features)

    @nw.narwhalify
    def predict(
            self, df: IntoFrameT, **kwargs
    ) -> IntoFrameT:
        """
        Generates either cross-validated or future predictions on the given dataframe.
        If cross_validation is set to True, lag-generators will continue to be calculated on the historical data.
        If cross_validation is set to False, it is assumed that df only contains future data, in which the transformed lag-values will be the same for all rows for the given granularity.

        :param df: DataFrame with the data to be used for training and prediction
        :param return_features: If True, the features generated by the pipeline will be returned in the output dataframe.
        """
        input_cols = df.columns

        df = nw.from_native(self._transform_pre_transformers(df=df))
        df = nw.from_native(self.predictor.predict(df))

        return df.select(input_cols + self.columns_added)

    def _create_pre_transformers(self, df: pl.DataFrame) -> list[PredictorTransformer]:
        pre_transformers = []
        cat_feats_to_transform = []

        for estimator_feature in self._features.copy():
            if not df[estimator_feature].dtype.is_numeric():
                cat_feats_to_transform.append(estimator_feature)

        for estimator_feature in self._features.copy():

            if estimator_feature not in df.columns:
                self._modified_features.remove(estimator_feature)
                logging.warning(
                    f"Feature {estimator_feature} not in df, removing from estimator_features"
                )
                continue

        if cat_feats_to_transform:
            if self.one_hot_encode_cat_features:
                one_hot_encoder = SkLearnTransformerWrapper(
                    transformer=OneHotEncoder(handle_unknown="ignore"),
                    features=cat_feats_to_transform,
                )
                pre_transformers.append(one_hot_encoder)

            elif self.convert_cat_features_to_cat_dtype:

                pre_transformers.append(
                    ConvertDataFrameToCategoricalTransformer(
                        features=cat_feats_to_transform
                    )
                )

        if self.scale_features:
            numeric_feats = [
                f for f in self._features if f not in cat_feats_to_transform
            ]
            if numeric_feats:
                pre_transformers.append(
                    SkLearnTransformerWrapper(
                        transformer=StandardScaler(),
                        features=numeric_feats,
                    )
                )

        if self.impute_missing_values:
            numeric_feats = [
                f for f in self._modified_features if f not in cat_feats_to_transform
            ]
            if numeric_feats:

                imputer_transformer = SkLearnTransformerWrapper(
                    transformer=SimpleImputer(),
                    features=numeric_feats,
                )
                if not self._transformer_exists(imputer_transformer):
                    pre_transformers.append(imputer_transformer)

        return pre_transformers

    def _transformer_exists(self, transformer: PredictorTransformer) -> bool:
        for pre_transformer in self.pre_transformers:
            if (
                    pre_transformer.__class__.__name__ == transformer.__class__.__name__
                    and pre_transformer.features == transformer.features
            ):
                return True
        return False

    def _fit_transform_pre_transformers(self, df: IntoFrameT) -> IntoFrameT:
        if self.auto_pre_transform:
            self.pre_transformers += self._create_pre_transformers(df)

        native_namespace = nw.get_native_namespace(df)

        for pre_transformer in self.pre_transformers:
            values = nw.from_native(pre_transformer.fit_transform(df))
            features_out = pre_transformer.features_out
            df = df.with_columns(
                nw.new_series(
                    values=values[col].to_native(),
                    name=features_out[idx],
                    backend=native_namespace,
                )
                for idx, col in enumerate(values.columns)
            )

            for feature in pre_transformer.features:
                if (
                        feature in self._modified_features
                        and feature not in pre_transformer.features_out
                ):
                    self._modified_features.remove(feature)
            for features_out in pre_transformer.features_out:
                if features_out not in self._modified_features:
                    self._modified_features.append(features_out)

        return df

    def _transform_pre_transformers(self, df: IntoFrameT) -> IntoFrameT:
        for pre_transformer in self.pre_transformers:
            values = nw.from_native(pre_transformer.transform(df))
            df = df.with_columns(
                nw.new_series(
                    name=col,
                    values=values[col].to_native(),
                    backend=nw.get_native_namespace(df),
                )
                for col in values.columns
            )
        return df