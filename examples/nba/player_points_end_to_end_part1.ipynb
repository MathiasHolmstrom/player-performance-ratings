{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d837261d-18a7-4c69-b04f-1c402c198c38",
   "metadata": {},
   "source": [
    "Imagine we are tasked with predicting the amount of points an NBA player will generate in a game. \n",
    "This notebook contains a step-by-step guide on how to model that using some of the tools by spforge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e2f45f-48c9-4a62-9ee3-356684b150a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>game_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>start_position</th>\n",
       "      <th>team_id_opponent</th>\n",
       "      <th>points</th>\n",
       "      <th>game_minutes</th>\n",
       "      <th>minutes</th>\n",
       "      <th>won</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>location</th>\n",
       "      <th>score</th>\n",
       "      <th>score_opponent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38956</th>\n",
       "      <td>1610612755</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>0022200001</td>\n",
       "      <td>202699</td>\n",
       "      <td>Tobias Harris</td>\n",
       "      <td>F</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>18.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.233</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>away</td>\n",
       "      <td>117</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38957</th>\n",
       "      <td>1610612755</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>0022200001</td>\n",
       "      <td>200782</td>\n",
       "      <td>P.J. Tucker</td>\n",
       "      <td>F</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>33.017</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>away</td>\n",
       "      <td>117</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38958</th>\n",
       "      <td>1610612755</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>0022200001</td>\n",
       "      <td>203954</td>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>C</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.267</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>away</td>\n",
       "      <td>117</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38959</th>\n",
       "      <td>1610612755</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>0022200001</td>\n",
       "      <td>1630178</td>\n",
       "      <td>Tyrese Maxey</td>\n",
       "      <td>G</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>21.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.200</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>away</td>\n",
       "      <td>117</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38960</th>\n",
       "      <td>1610612755</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>0022200001</td>\n",
       "      <td>201935</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>G</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>35.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.267</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>away</td>\n",
       "      <td>117</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          team_id  start_date     game_id  player_id    player_name  \\\n",
       "38956  1610612755  2022-10-18  0022200001     202699  Tobias Harris   \n",
       "38957  1610612755  2022-10-18  0022200001     200782    P.J. Tucker   \n",
       "38958  1610612755  2022-10-18  0022200001     203954    Joel Embiid   \n",
       "38959  1610612755  2022-10-18  0022200001    1630178   Tyrese Maxey   \n",
       "38960  1610612755  2022-10-18  0022200001     201935   James Harden   \n",
       "\n",
       "      start_position  team_id_opponent  points  game_minutes  minutes  won  \\\n",
       "38956              F        1610612738    18.0          48.0   34.233    0   \n",
       "38957              F        1610612738     6.0          48.0   33.017    0   \n",
       "38958              C        1610612738    26.0          48.0   37.267    0   \n",
       "38959              G        1610612738    21.0          48.0   38.200    0   \n",
       "38960              G        1610612738    35.0          48.0   37.267    0   \n",
       "\n",
       "       plus_minus location  score  score_opponent  \n",
       "38956        -1.0     away    117             126  \n",
       "38957        -6.0     away    117             126  \n",
       "38958       -13.0     away    117             126  \n",
       "38959        -6.0     away    117             126  \n",
       "38960         1.0     away    117             126  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from spforge.transformers import LagTransformer, RollingMeanTransformer\n",
    "df = pd.read_parquet(\"data/game_player_subsample.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04cdbb91-ff84-45b4-92dc-ffd7e2f0e55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 2022-10-18 to 2023-02-01 | Total rows: 19,872 | Unique games: 776\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data from {df['start_date'].min()} to {df['start_date'].max()} | \"\n",
    "      f\"Total rows: {len(df):,} | Unique games: {df['game_id'].nunique():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c787e-a845-4669-8a33-ba83313827fc",
   "metadata": {},
   "source": [
    "To start, let's quickly check if the data roughly matches what we expect given domain knowledge. Do the highes scoring NBA players such as Luca Doncic and Giannis have the highest points per game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041306f5-9033-4035-82e3-c7bd79f71da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "if importlib.util.find_spec(\"seaborn\") is None:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"seaborn\"])\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_avg = (\n",
    "    df.groupby('player_name')['points']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(by='points', ascending=False)\n",
    ").head(20)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(\n",
    "    data=df_avg,\n",
    "    y='player_name',\n",
    "    x='points',\n",
    "    palette='viridis'  \n",
    ")\n",
    "\n",
    "plt.title('Average Points per Player', fontsize=16, weight='bold')\n",
    "plt.xlabel('Average Points', fontsize=12)\n",
    "plt.ylabel('Player', fontsize=12)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e8720-df74-469e-82c8-609dc4b9c7ea",
   "metadata": {},
   "source": [
    "Some of the features that could be predictive of future points scored:\n",
    "* Previous Points scored\n",
    "* Previous Minutes played\n",
    "* Previous points_per_minute\n",
    "\n",
    "In spforge, we can calculate a players past performances in a few different ways. One of the more straight-forward approaches is through a RollingMeanTransformer as seen below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc5e52-7654-4d6a-977d-a3a3b452016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['points_per_minute'] = df['points'] / df['minutes']\n",
    "df = df.sort_values(by=['start_date'])\n",
    "rm_transformer_window20 = RollingMeanTransformer(\n",
    "    features=['points', 'points_per_minute', 'minutes'],\n",
    "    granularity=['player_id'],\n",
    "    window=20,\n",
    "    update_column='game_id'\n",
    ")\n",
    "df = rm_transformer_window20.transform_historical(df)\n",
    "df[['player_name',*rm_transformer_window20.features_out]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fac0c1-1c62-4e1a-a06f-1d73e690a441",
   "metadata": {},
   "source": [
    "Below is Jayson Tatum's 20-window Rolling Mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917b302-6ecb-4321-b26f-7a1d61f43818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['player_name']=='Jayson Tatum'].set_index('start_date')['rolling_mean_points20'].plot(title=\"Jayson Tatum Rolling Mean Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39dfe4-e8e6-4d5d-9814-d49889f06fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[*rm_transformer_window20.features_out, 'points']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc2148-c6e8-4625-813c-c68960313bd9",
   "metadata": {},
   "source": [
    "All of the 3 features correlate quite strongly with points scored which indicate that they make sense to use as features to our final machine-learning model.\n",
    "Below we split into train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154650c6-8ccb-44d5-b5c5-2136d2f2fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "unique_dates = df['start_date'].unique().tolist()\n",
    "train_max_date = unique_dates[int(len(unique_dates)*0.7)]\n",
    "train = df[df['start_date']<=train_max_date]\n",
    "test = df[df['start_date']>train_max_date]\n",
    "len(train), len(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a25285-b3e8-46b5-adbd-adf28c381f80",
   "metadata": {},
   "source": [
    "We use a LGBMRegressor as the machine-learning model with a low max_depth as we only have 3 features with a relatively straight-forward relationship with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e3136-1307-43a7-9796-1d35bf91e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = rm_transformer_window20.features_out\n",
    "estimator =LGBMRegressor(verbose=-100, max_depth=3)\n",
    "estimator.fit(train[features], train['points'])\n",
    "feature_importances = [f/sum(estimator.feature_importances_) for f in estimator.feature_importances_]\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fd2c5-5b6c-4744-be31-b6f69d171e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predicted_points'] = estimator.predict(test[features])\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(test['points'], test['predicted_points'])\n",
    "print(f\"Mean absolute error: {mae}\")\n",
    "\n",
    "df_avg = (\n",
    "    test.groupby('player_name')['predicted_points']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(by='predicted_points', ascending=False)\n",
    ").head(20)\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(\n",
    "    data=df_avg,\n",
    "    y='player_name',\n",
    "    x='predicted_points',\n",
    "    palette='viridis' \n",
    ")\n",
    "\n",
    "\n",
    "plt.title('Average Predicted Points per Player', fontsize=16, weight='bold')\n",
    "plt.xlabel('Average Predicted Points', fontsize=12)\n",
    "plt.ylabel('Player', fontsize=12)\n",
    "\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bf4f9d-7b50-425f-947b-f994b86dccba",
   "metadata": {},
   "source": [
    "Above we can see that the predicted points generally aligns with what we expected from the entire historical dataset.\n",
    "This indicates that the model's output isn't completely off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7095a04-fdd4-4f38-9d59-4d713f041c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(test['points'], test['predicted_points'])\n",
    "print(f\"Mean absolute error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383159e-1e39-4988-8470-6bd7f3041d7c",
   "metadata": {},
   "source": [
    "The mean absolute error is 4.27.\n",
    "\n",
    "We can probably improve upon that by adding additional features. Instead of only having a single window =20 for rolling mean, let's try and add multiple windows of different lengths and let's also add the past 5 lags for the player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44bf837-d64d-444b-84dd-fe7408e24dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_transformer_window10 = RollingMeanTransformer(\n",
    "    features=['points', 'points_per_minute', 'minutes'],\n",
    "    granularity=['player_id'],\n",
    "    window=10,\n",
    "    update_column='game_id'\n",
    ")\n",
    "df = rm_transformer_window10.transform_historical(df)\n",
    "rm_transformer_window5 = RollingMeanTransformer(\n",
    "    features=['points', 'points_per_minute', 'minutes'],\n",
    "    granularity=['player_id'],\n",
    "    window=5,\n",
    "    update_column='game_id'\n",
    ")\n",
    "df = rm_transformer_window5.transform_historical(df)\n",
    "rm_transformer_window40 = RollingMeanTransformer(\n",
    "    features=['points', 'points_per_minute', 'minutes'],\n",
    "    granularity=['player_id'],\n",
    "    window=40,\n",
    "    update_column='game_id'\n",
    ")\n",
    "df = rm_transformer_window40.transform_historical(df)\n",
    "\n",
    "lag_transformer = LagTransformer(\n",
    "    features=['points', 'points_per_minute', 'minutes'],\n",
    "    granularity=['player_id'],\n",
    "    lag_length=5,\n",
    "    update_column='game_id'\n",
    ")\n",
    "df = lag_transformer.transform_historical(df)\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60153ed9-9687-489e-a7bf-fc5dd2fd1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = (rm_transformer_window20.features_out +\n",
    "lag_transformer.features_out +\n",
    "rm_transformer_window10.features_out +\n",
    "rm_transformer_window5.features_out+ \n",
    "rm_transformer_window40.features_out)\n",
    "train = df[df['start_date']<=train_max_date]\n",
    "test = df[df['start_date']>train_max_date]\n",
    "estimator_all_feats =LGBMRegressor(verbose=-100, max_depth=3, random_state=42)\n",
    "estimator_all_feats.fit(train[all_features], train['points'])\n",
    "feature_importances = [f/sum(estimator_all_feats.feature_importances_) for f in estimator_all_feats.feature_importances_]\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.bar(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c8c22-9bf2-4d1d-a58d-13b834fccf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'predicted_points_all_features'] = estimator_all_feats.predict(test[all_features])\n",
    "mae = mean_absolute_error(test['points'], test['predicted_points_all_features'])\n",
    "print(f\"Mean absolute error All Features Model: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeb8f6f-83c7-4a56-b115-b91f7134c2cc",
   "metadata": {},
   "source": [
    "As expected we get a better mean absolute error. \n",
    "\n",
    "However, this process has been a bit tedious. We had to manually add all the features from the various transformers. We had to create the train-test split ourself. And we didn't even utilise proper cross-validation with multiple splits. If we had add more splits, it would be even more complex. \n",
    "\n",
    "And while we so far are only exploring historical data. How would we go about implementing the lag-and-rolling mean transformers for future games. To calculate future games, it would need to have acccess to the historical data as well which increases complexity. \n",
    "\n",
    "Luckily, the spforge Pipeline is designed to do all of these things with little input from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e33905-c75d-46a0-ac23-a68bbe202058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spforge import Pipeline, ColumnNames\n",
    "from spforge.predictor import SklearnPredictor\n",
    "#Reloading original dataframe to ensure we start all over from scratch\n",
    "df = pd.read_parquet(\"data/game_player_subsample.parquet\")\n",
    "df['points_per_minute'] = df['points'] / df['minutes']\n",
    "train = df[df['start_date']<=train_max_date]\n",
    "test = df[df['start_date']>train_max_date]\n",
    "column_names = ColumnNames(\n",
    "    team_id=\"team_id\",\n",
    "    match_id=\"game_id\",\n",
    "    start_date=\"start_date\",\n",
    "    player_id=\"player_id\"    \n",
    ")\n",
    "predictor = SklearnPredictor(estimator=LGBMRegressor(max_depth=4,verbose=-100), target='points')\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    lag_transformers = [lag_transformer, rm_transformer_window5, rm_transformer_window10, rm_transformer_window20, rm_transformer_window40],\n",
    "    predictor = predictor,\n",
    "    column_names=column_names\n",
    ")\n",
    "\n",
    "pipeline.train(train)\n",
    "test = pipeline.predict(test, cross_validation=True, return_features=True)\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d5dad1-ed90-44b2-a628-8b975b24ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(test['points'], test[pipeline.pred_column])\n",
    "print(f\"Mean absolute error Pipeline Model: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d027b-5832-44bf-81c4-8b24862421ac",
   "metadata": {},
   "source": [
    "As seen below the same features are used by the LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d860b10-5491-4336-a178-295610e8c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.predictor.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4905553f-de82-41d2-883c-835ac4e99ec7",
   "metadata": {},
   "source": [
    "More experienced users of machine-learning may be aware that performing only a single train-test split is not the best practice. Ideally we perform cross_validation with multiple splits. \n",
    "\n",
    "spforge has support for that as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80927933-1c89-4bdd-8f04-9c049b351ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spforge.cross_validator import MatchKFoldCrossValidator\n",
    "\n",
    "cross_validator = MatchKFoldCrossValidator(\n",
    "    match_id_column_name='game_id',\n",
    "    date_column_name='start_date',\n",
    "    predictor = pipeline,\n",
    ")\n",
    "df = cross_validator.generate_validation_df(df,  add_train_prediction=True, return_features=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb7432-77f2-4d26-85d2-9178ce3f6ec5",
   "metadata": {},
   "source": [
    "Note that we added a parameter to return predictions for the non-validated (training) data-split as well. There is a column is_validation that flags whether the predictions are from the non-validated predictions. \n",
    "\n",
    "Returning the non-validating predictions can be useful to evaluate difference between training data and validation data accuracy. But also in case where the prediction-output will be used as an input to another model.\n",
    "\n",
    "To measure the cross-validated mean_absolute_error we need to import an Sklearn Scorer Wrapper. This wrapper will automatically filter out the training-data predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c66bb-8bbc-41bb-9ffa-f554f24df595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spforge.scorer import SklearnScorer\n",
    "mean_absolute_scorer = SklearnScorer(pred_column=pipeline.pred_column, scorer_function=mean_absolute_error, target='points')\n",
    "cross_validator.cross_validation_score(df, scorer=mean_absolute_scorer )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c74371-a517-4feb-91de-7c8c3255d3c6",
   "metadata": {},
   "source": [
    "Some readers may think: But what about the opponent? So far we only evaluated using the players own historical stats. But if a player is facing a strong team chances are he will score fewer points. \n",
    "\n",
    "There are a few ways we can handle that. The simplest approach is to add the opponent as a categorical feature. \n",
    "Because we already calculated the lag-and-rolling-mean features we don't need to recalculate them. Because the pipeline has the same methods as a normal predictor, any predictor type can also be passed into MatchKFoldCrossValidator instead of the pipeline.\n",
    "\n",
    "Instead we need to the opponent as a categorical feature along with the features generated by the pipeline. \n",
    "We also set convert_cat_features_to_cat_dtype to True. This ensures non-numeric features are converted to categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b0ad2-7de2-41b3-9737-13a2f4d50823",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cat_feats = SklearnPredictor(estimator=LGBMRegressor(max_depth=4,verbose=-100), target='points', features = ['team_id_opponent',*pipeline.features], \n",
    "                                       convert_cat_features_to_cat_dtype=True)\n",
    "\n",
    "cross_validator_cat_feats = MatchKFoldCrossValidator(\n",
    "    match_id_column_name='game_id',\n",
    "    date_column_name='start_date',\n",
    "    predictor = predictor_cat_feats,\n",
    ")\n",
    "df = cross_validator_cat_feats.generate_validation_df(df,  add_train_prediction=True)\n",
    "cross_validator_cat_feats.cross_validation_score(df, scorer=mean_absolute_scorer )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43aa9b-88eb-4913-9695-328de86ab025",
   "metadata": {},
   "source": [
    "This shows a small improvement. There are definitely better and more dynamic ways to take into account opponent. Rating Models are one way of doing that, but it's beyond the scope of this guide. \n",
    "\n",
    "Finally, let's assume we have a future match which we want to generate predictions for. So far we only performed cross-validation, but we never trained the pipline on the entire dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bbe291-f1bf-4a83-b3a1-338776d29328",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictor = SklearnPredictor(estimator=LGBMRegressor(max_depth=4,verbose=-100), target='points', features = ['team_id_opponent'], \n",
    "                                       convert_cat_features_to_cat_dtype=True)\n",
    "final_pipeline = Pipeline(\n",
    "    lag_transformers = [lag_transformer, rm_transformer_window5, rm_transformer_window10, rm_transformer_window20, rm_transformer_window40],\n",
    "    predictor = final_predictor,\n",
    "    column_names=column_names\n",
    ")\n",
    "\n",
    "final_pipeline.train(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63851b5c-5983-4f0a-b61d-cab0e9826144",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_id_1= df['team_id'].iloc[0]\n",
    "team_id_2= df['team_id_opponent'].iloc[1]\n",
    "player_id_stephen_curry = df[df['player_name']=='Stephen Curry']['player_id'].iloc[1]\n",
    "player_id_jayson_tatum = df[df['player_name']=='Jayson Tatum']['player_id'].iloc[1]\n",
    "player_id_kevin_durant = df[df['player_name']=='Kevin Durant']['player_id'].iloc[1]\n",
    "player_id_trae_young = df[df['player_name']=='Trae Young']['player_id'].iloc[1]\n",
    "future_game = pd.DataFrame(\n",
    "    {\n",
    "        \"game_id\": [\"99999\"]* 4,\n",
    "        \"start_date\": [pd.to_datetime(df['start_date'].max()) + pd.Timedelta(days=1)]*4,\n",
    "        'team_id': [team_id_1, team_id_1, team_id_2, team_id_2 ],\n",
    "        'team_id_opponent': [team_id_2, team_id_2, team_id_1, team_id_1 ],\n",
    "        'player_id': [player_id_stephen_curry, player_id_jayson_tatum, player_id_kevin_durant, player_id_trae_young],\n",
    "        'player_name':['Stephen Curry', 'Jayson Tatum', 'Kevin Durant', 'Trae Young']\n",
    "    }\n",
    ")\n",
    "future_game.head()\n",
    "final_pipeline.predict(future_game, return_features=True).head()[['player_name', final_pipeline.pred_column]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88623645-bb85-403a-999b-185b55f9b3a7",
   "metadata": {},
   "source": [
    "The above example is obviously a nonsensical 2x2 match. The model knows nothing about the team-mates nor the amount of players on the opposing team. Thus it will generate pretty naive predictions that assumes a \"normal\" game."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
